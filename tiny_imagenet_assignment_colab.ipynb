{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d67f365",
   "metadata": {},
   "source": [
    "### Environment and Device Check  \n",
    "Before training the model, it is important to verify that TensorFlow is installed correctly and to identify which devices are available for computation.  \n",
    "This cell prints the TensorFlow version, lists all logical devices detected by TensorFlow, and reports the number of GPUs available.  \n",
    "This determines whether training will run on CPU or GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d269c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Available devices:\")\n",
    "for d in tf.config.list_logical_devices():\n",
    "    print(\" \", d)\n",
    "\n",
    "print(\"Num GPUs:\", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f95e085",
   "metadata": {},
   "source": [
    "### Install kagglehub  \n",
    "This project uses Tiny-ImageNet downloaded through **kagglehub**, so we need to install the package before accessing the dataset.  \n",
    "This cell installs kagglehub inside the current environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19fda9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kagglehub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e1e339",
   "metadata": {},
   "source": [
    "### Download Tiny-ImageNet  \n",
    "We use `kagglehub` to download the Tiny-ImageNet dataset.  \n",
    "This block retrieves the dataset, prints the local path, and sets the project root directory so later cells can load images correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf81cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "path = kagglehub.dataset_download(\"akash2sharma/tiny-imagenet\")\n",
    "print(\"Dataset downloaded to:\", path)\n",
    "\n",
    "root = os.path.join(path, \"tiny-imagenet-200\")\n",
    "print(\"Using:\", root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8442bb2",
   "metadata": {},
   "source": [
    "### Reorganize Validation Set  \n",
    "Tiny-ImageNet ships the validation images inside one folder with a separate annotations file.  \n",
    "This cell reads the annotation file, creates class-specific subfolders, and moves images into their correct class directories.  \n",
    "This ensures Keras generators correctly map labels during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ecebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "val_dir = os.path.join(root, \"val\")\n",
    "val_images = os.path.join(val_dir, \"images\")\n",
    "annotations_file = os.path.join(val_dir, \"val_annotations.txt\")\n",
    "\n",
    "df = pd.read_csv(annotations_file, sep=\"\\t\", header=None)\n",
    "df.columns = [\"filename\", \"class\", \"x1\", \"y1\", \"x2\", \"y2\"]\n",
    "\n",
    "# Create class dirs\n",
    "for c in df[\"class\"].unique():\n",
    "    class_dir = os.path.join(val_dir, c)\n",
    "    os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "# Move images\n",
    "for _, row in df.iterrows():\n",
    "    src = os.path.join(val_images, row[\"filename\"])\n",
    "    dst = os.path.join(val_dir, row[\"class\"], row[\"filename\"])\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dst)\n",
    "\n",
    "print(\"Validation set reorganized.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d79f5c",
   "metadata": {},
   "source": [
    "### Build Train and Validation Generators  \n",
    "This cell creates `ImageDataGenerator` pipelines for the Tiny ImageNet training and validation sets.  \n",
    "Images are resized to 64x64 and normalized to the range [0, 1].  \n",
    "Both generators produce one-hot encoded labels for the 200 classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0824b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1.0/255)\n",
    "val_gen   = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_generator = train_gen.flow_from_directory(\n",
    "    os.path.join(root, \"train\"),\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_generator = val_gen.flow_from_directory(\n",
    "    os.path.join(root, \"val\"),\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cd63f7",
   "metadata": {},
   "source": [
    "### Inspect a Sample Batch  \n",
    "This cell fetches the next batch from the training generator and verifies:\n",
    "- The image tensor shape  \n",
    "- The one hot label shape  \n",
    "- That each label vector sums to 1  \n",
    "- What unique class indices appear in the batch  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5840f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(train_generator)\n",
    "print(\"Batch X:\", x.shape)\n",
    "print(\"Batch Y:\", y.shape)\n",
    "print(\"Row sums:\", y.sum(axis=1)[:10])\n",
    "print(\"Unique labels:\", sorted(list(set(y.argmax(axis=1)))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acd309d",
   "metadata": {},
   "source": [
    "### Define the Custom ResNet-18 Model  \n",
    "This cell implements a lightweight ResNet-18 suitable for Tiny-ImageNet.  \n",
    "It includes:  \n",
    "- A residual block with optional projection  \n",
    "- Downsampling at each stage  \n",
    "- Global average pooling  \n",
    "- Final softmax classification head  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4397da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def residual_block(x, filters, stride=1, use_projection=False, name=None):\n",
    "    shortcut = x\n",
    "\n",
    "    x = layers.Conv2D(filters, 3, stride, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    if use_projection:\n",
    "        shortcut = layers.Conv2D(filters, 1, stride, padding=\"same\", use_bias=False)(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def build_resnet18(input_shape=(64, 64, 3), num_classes=200):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\", use_bias=False)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = residual_block(x, 64, stride=1, use_projection=False)\n",
    "    x = residual_block(x, 64, stride=1, use_projection=False)\n",
    "\n",
    "    x = residual_block(x, 128, stride=2, use_projection=True)\n",
    "    x = residual_block(x, 128, stride=1, use_projection=False)\n",
    "\n",
    "    x = residual_block(x, 256, stride=2, use_projection=True)\n",
    "    x = residual_block(x, 256, stride=1, use_projection=False)\n",
    "\n",
    "    x = residual_block(x, 512, stride=2, use_projection=True)\n",
    "    x = residual_block(x, 512, stride=1, use_projection=False)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    return models.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34eb4a8",
   "metadata": {},
   "source": [
    "### Compile the ResNet-18 Model  \n",
    "We compile using Adam with a stable learning rate.  \n",
    "Loss is categorical cross entropy because Tiny-ImageNet labels are one hot.  \n",
    "Accuracy is tracked along with planned later metrics (Top 5 accuracy).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71626d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_resnet18()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.TopKCategoricalAccuracy(k=5, name=\"top5_accuracy\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c21c3b",
   "metadata": {},
   "source": [
    "### Add Training Callbacks  \n",
    "We include two callbacks to stabilize training:\n",
    "\n",
    "1. **EarlyStopping**  \n",
    "   Stops training when validation accuracy stops improving.  \n",
    "   This prevents overfitting and wasted compute.\n",
    "\n",
    "2. **ModelCheckpoint**  \n",
    "   Saves the best performing model during training.  \n",
    "   We will reload this model later for final evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f7771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "checkpoint_path = \"best_resnet18.h5\"\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7831b7ee",
   "metadata": {},
   "source": [
    "### Train the ResNet-18 Model  \n",
    "We now begin full training using the GPU.  \n",
    "The model will run for up to 20 epochs, but **EarlyStopping** may stop it earlier if validation accuracy plateaus.\n",
    "\n",
    "Training includes:\n",
    "- Feedforward and backprop on the training set  \n",
    "- Validation tracking every epoch  \n",
    "- Checkpoint saving for the best model  \n",
    "- Early stopping to avoid overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47aa9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20  # GPU-friendly\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09229d1",
   "metadata": {},
   "source": [
    "### Plot Training Curves  \n",
    "To understand learning behavior, we plot both accuracy and loss for training and validation.  \n",
    "This helps visualize:\n",
    "- Whether the model is overfitting  \n",
    "- Whether accuracy is improving across epochs  \n",
    "- If loss is decreasing or plateauing  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b06a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val\")\n",
    "plt.title(\"Accuracy\"); plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history[\"loss\"], label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val\")\n",
    "plt.title(\"Loss\"); plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02533b95",
   "metadata": {},
   "source": [
    "### Collect Model Predictions for Confusion Matrix  \n",
    "We gather predictions for the entire validation set by iterating over the validation generator.  \n",
    "Steps:  \n",
    "1. Reverse the `class_indices` mapping to convert integer predictions back to class names.  \n",
    "2. Loop through all validation batches.  \n",
    "3. Collect ground truth labels (`y_true`) and predicted labels (`y_pred`).  \n",
    "4. Convert them to numpy arrays for confusion matrix computation.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3df9244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get class order\n",
    "class_indices = train_generator.class_indices\n",
    "idx_to_class = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "# Predict all validation samples\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "val_generator.reset()\n",
    "\n",
    "for _ in range(len(val_generator)):\n",
    "    batch_x, batch_y = next(val_generator)\n",
    "    preds = model.predict(batch_x, verbose=0)\n",
    "    y_true.extend(np.argmax(batch_y, axis=1))\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "print(\"Prediction collection complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58cee57",
   "metadata": {},
   "source": [
    "### Confusion Matrix Visualization and Export  \n",
    "To evaluate how well the model distinguishes between different categories, we compute the confusion matrix across all 200 classes.  \n",
    "Since plotting all 200 categories at once becomes unreadable, we visualize only the first 20 classes as a heatmap.  \n",
    "\n",
    "Steps:  \n",
    "1. Compute the full confusion matrix using all validation predictions.  \n",
    "2. Extract a smaller 20x20 subset for readable visualization.  \n",
    "3. Plot a heatmap with seaborn.  \n",
    "4. Save the full confusion matrix as a CSV file for further analysis or reporting.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62586a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion matrix shape:\", cm.shape)\n",
    "\n",
    "subset_classes = list(range(20))\n",
    "\n",
    "cm_subset = cm[np.ix_(subset_classes, subset_classes)]\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cm_subset, annot=False, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix (first 20 classes)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "df_cm = pd.DataFrame(cm)\n",
    "df_cm.to_csv(\"tiny_imagenet_confusion_matrix.csv\", index=False)\n",
    "print(\"Confusion matrix saved to tiny_imagenet_confusion_matrix.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3284120d",
   "metadata": {},
   "source": [
    "### Evaluating the Best Saved Model  \n",
    "After training with early stopping and checkpointing, the model with the highest validation accuracy is loaded from disk.  \n",
    "To measure performance, we compute:  \n",
    "\n",
    "- Final loss on the validation set  \n",
    "- Top 1 accuracy  \n",
    "- Top 5 accuracy  \n",
    "\n",
    "Top 1 accuracy indicates whether the highest softmax probability matches the true class.  \n",
    "Top 5 accuracy checks whether the correct label appears within the five most likely predictions.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43edd994",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model(\"best_resnet18.h5\")\n",
    "\n",
    "results = best_model.evaluate(val_generator)\n",
    "print(\"Best model results:\", results)\n",
    "print(\"Top 1 accuracy:\", results[1])\n",
    "print(\"Top 5 accuracy:\", results[2])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
